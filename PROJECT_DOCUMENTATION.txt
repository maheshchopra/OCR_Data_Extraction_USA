UTILITY BILL PROCESSING SYSTEM - PROJECT DOCUMENTATION
================================================================================

PROJECT OVERVIEW
================================================================================

This project is an automated utility bill data extraction system that processes PDF utility bills from various providers and municipalities, extracting structured billing information using AI-powered vision models. The system is designed to handle multiple utility providers across different regions, with specialized templates for each provider's unique bill format.

The system converts unstructured PDF utility bills into structured JSON data, enabling automated processing, validation, and analysis of billing information. It supports over 30 different utility providers including municipal utilities, energy companies, water districts, and waste management services.

KEY FEATURES
================================================================================

Company Detection and Template Selection
The system employs a two-stage detection mechanism to identify the utility provider from each bill. First, it attempts filename-based detection by matching keywords in the PDF filename against known provider identifiers. If filename detection fails, the system uses GPT-4o Vision AI to analyze the first page of the bill and identify the provider by examining logos, headers, and company identification information. Once a provider is detected, the system selects a specialized extraction template optimized for that provider's bill format.

Multi-Provider Support
The system includes specialized extraction templates for over 30 utility providers, each with custom instructions tailored to the specific format and data structure of that provider's bills. Supported providers include municipal utilities (City of Redmond, City of Everett, City of Kent, etc.), energy companies (Puget Sound Energy, Seattle City Light), water districts (King County Water District, Snohomish County PUD), and waste management services (Waste Management, Recology). Each template includes provider-specific field mappings and extraction rules.

Comprehensive Data Extraction
The system extracts a wide range of billing information including account details (account number, customer name, service address, billing address), billing period information (bill date, due date, service period dates, number of days), financial information (previous balance, current billing, adjustments, payments applied, total amount due), service details (service types, line item charges, meter readings, usage data), tax information (per-service taxes, global taxes with rates and amounts), and provider contact information (website, phone, email, addresses).

Billing Validation
The system includes comprehensive validation logic that verifies the accuracy of extracted billing amounts. Different validation strategies are used based on the provider's billing structure. For standard bills, it validates that the sum of service charges plus adjustments equals the current billing amount. For meter-based bills (like Puget Sound Energy), it validates that the sum of all meter totals equals the total amount due. For bills with detailed breakdowns (like Seattle City Light), it validates that the sum of detailed amounts equals the current billing. For waste management bills, it validates services plus taxes plus adjustments. The validation includes tolerance for rounding differences (less than $0.01) and provides detailed validation reports.

Batch Processing
The system can process multiple PDF files in batches, with configurable batch sizes and delays between batches. This allows for efficient processing of large volumes of bills while managing API rate limits and system resources. The batch processing includes progress tracking, error handling, and comprehensive logging.

File Organization
After processing, the system automatically organizes files into structured directories based on extraction success. Successfully processed bills are moved to processed/pdf and processed/json directories, while bills with incomplete or failed extractions are moved to unprocessed/pdf and unprocessed/json directories. The system determines extraction success based on the presence of meaningful data across multiple categories (customer information, billing information, address information, service information, tax information).

Comprehensive Logging
Every run of the system creates a timestamped log file that captures all output, errors, and processing details. This enables debugging, auditing, and tracking of processing history. Logs are stored in a dedicated logs directory with clear timestamps.

TECHNICAL ARCHITECTURE
================================================================================

Core Processing Pipeline
The main processing pipeline begins with PDF discovery, where the system scans an inbox directory for PDF files. Each PDF is converted to high-resolution images (300 DPI) using the pdf2image library. All pages of the PDF are processed together in a single API call to the GPT-4o Vision model, which analyzes the images and extracts structured data according to the selected template. The extracted data is then validated, enriched with template-specific fields, and saved as JSON alongside the original PDF.

AI-Powered Extraction
The system uses OpenAI's GPT-4o Vision model for document understanding and data extraction. PDF pages are converted to PNG images, encoded as base64, and sent to the vision API along with detailed extraction prompts. The prompts are carefully crafted to guide the AI in identifying and extracting specific fields while handling variations in bill formats. The system uses JSON mode to ensure structured output.

Template System
The template system consists of three layers. The base layer (prompt_templates.py) defines common extraction fields and JSON structure. The child prompts layer (child_prompts/) contains provider-specific extraction instructions that extend the base template with detailed guidance for each provider's unique format. The company templates layer (company_templates/) contains post-processing handlers that ensure provider-specific fields are present in the extracted data, even if they were not explicitly extracted.

Validation Framework
The validation framework includes multiple validation functions tailored to different billing structures. validate_billing_amounts handles standard bills where services plus adjustments should equal current billing. validate_meter_based_billing handles bills where multiple meters contribute to the total. validate_amounts_based_billing handles bills with detailed amount breakdowns. validate_waste_management_billing handles bills where services, taxes, and adjustments must sum correctly. All validators parse dollar amounts, handle rounding, and provide detailed validation reports.

HOW THE CODE WORKS
================================================================================

Main Entry Point (main function)
The main function sets up command-line argument parsing for optional PDF path, batch size, and batch delay parameters. It initializes per-run logging, creates the required folder structure, and then either processes a single specified PDF file or discovers and processes all PDFs in the inbox directory. For batch processing, it divides files into batches, processes each batch sequentially with configurable delays, and provides comprehensive progress reporting and final summaries.

PDF to Image Conversion (extract_bill_data_via_llm function)
The extraction function first attempts company detection from the filename. If that fails, it uses AI-based detection by converting the first page of the PDF to an image and sending it to GPT-4o Vision with a detection prompt. Once the company is identified, the appropriate extraction prompt template is selected. The function then converts all PDF pages to images at 300 DPI, encodes them as base64, and sends them along with the extraction prompt to GPT-4o Vision in a single API call.

Data Extraction and Parsing
The GPT-4o Vision API returns a JSON response containing all extracted fields. The system parses this JSON and extracts individual fields including account information, billing details, financial amounts, service types, taxes, and adjustments. The extracted data is then passed through the ensure_template_specific_fields function to add any provider-specific fields that may be required.

Template-Specific Field Enrichment (ensure_template_specific_fields function)
This function ensures that all required fields are present in the extracted data, even if they were not explicitly extracted. It first ensures general top-level fields exist (provider information, bill numbers, balances, service days, descriptions). It then ensures late fee information structure is present. Finally, it calls the provider-specific handler from the company_templates module to add any additional provider-specific fields required by that provider's template.

Billing Validation
After field enrichment, the system performs billing validation based on the detected provider. Different providers use different validation strategies. For example, Everett Public Works, Kent Utility, and City of Redmond use current_charges arrays for validation. Puget Sound Energy (both Electric and Gas) validates meter totals. Seattle City Light validates detailed amounts. Waste Management and Recology validate services plus taxes. The validation results are added to the extracted data structure.

File Organization (organize_files function)
The organize_files function determines whether extraction was successful by checking if meaningful data exists across multiple categories (customer info, billing info, address info, service info, tax info). At least two categories must have data for extraction to be considered successful. Based on this determination, files are moved to either processed or unprocessed directories, and JSON output is saved to the corresponding JSON directory.

Batch Processing (process_batch function)
The batch processing function processes a group of PDF files, handling each file individually with try-except error handling. For each file, it calls the extraction function, organizes the file, and tracks success and failure counts. If extraction fails, it creates an error result structure with all fields set to null and still organizes the file appropriately. The function provides batch-level progress reporting and summary statistics.

Logging System (setup_run_logging function)
The logging system creates a timestamped log file for each run and uses a custom TeeStream class to duplicate all stdout and stderr output to both the console and the log file. This ensures that all processing information is captured for later review while still providing real-time feedback to the user. The log file includes a header with timestamp, Python version, process ID, and working directory.

TECHNOLOGIES AND DEPENDENCIES
================================================================================

Python Libraries
The system is built using Python and relies on several key libraries. The OpenAI library provides access to GPT-4o Vision API for document understanding and data extraction. The pdf2image library converts PDF files to images for processing. PIL (Pillow) handles image manipulation and optimization. Standard library modules handle file operations, JSON processing, argument parsing, and system operations.

External Services
The system integrates with OpenAI's GPT-4o Vision API for document analysis. The API key is retrieved from system environment variables (OPENAI_API_KEY), following security best practices for credential management.

File Structure
The project uses a modular structure with separate directories for child prompts (provider-specific extraction instructions), company templates (post-processing handlers), processed files (successful extractions), unprocessed files (failed or incomplete extractions), inbox (input PDFs), and logs (processing history). This organization enables easy maintenance, extension, and debugging.

USE CASES
================================================================================

Automated Bill Processing
The system enables automated processing of utility bills for property management companies, accounting firms, or individuals who need to process large volumes of utility bills. Instead of manual data entry, bills can be placed in the inbox directory and processed in batches.

Data Analysis and Reporting
The structured JSON output enables downstream analysis, reporting, and integration with other systems. The consistent data structure across different providers allows for unified analysis of utility costs, usage patterns, and billing trends.

Billing Verification
The validation features help identify discrepancies in billing amounts, ensuring that extracted data accurately reflects the bill contents. This is valuable for auditing and error detection.

Multi-Provider Support
The system's ability to handle multiple providers with specialized templates makes it suitable for organizations that deal with properties across different municipalities and utility districts, where each may have different bill formats.

SCALABILITY AND PERFORMANCE
================================================================================

Batch Processing
The batch processing capability allows the system to handle large volumes of bills efficiently. Configurable batch sizes and delays help manage API rate limits and system resources while processing hundreds or thousands of bills.

Error Handling
Comprehensive error handling ensures that processing continues even if individual bills fail. Failed bills are logged and organized appropriately, allowing for manual review and reprocessing if needed.

Resource Management
The system includes cleanup mechanisms for temporary image files created during processing. It also uses optimized image encoding and efficient API usage patterns to minimize processing time and costs.

EXTENSIBILITY
================================================================================

Adding New Providers
The system is designed for easy extension. Adding support for a new utility provider involves creating a new child prompt file with provider-specific extraction instructions and optionally a company template handler for provider-specific fields. The provider is then registered in the prompt_templates.py registry with appropriate identifiers for detection.

Custom Validation
New validation strategies can be added by creating validation functions following the existing patterns and integrating them into the validation logic in the main extraction function.

PROJECT STATISTICS
================================================================================

The system supports over 30 different utility providers across multiple states, with specialized extraction templates for each. The codebase includes comprehensive validation logic, error handling, and logging. The modular architecture enables easy maintenance and extension. The system has been tested on hundreds of utility bills from various providers, demonstrating its robustness and accuracy.

================================================================================
END OF DOCUMENTATION
================================================================================

